{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9932892,"sourceType":"datasetVersion","datasetId":6105994}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import nltk \nimport numpy as np\nimport scipy\nimport pandas as pd\nimport math\nimport random\nimport sklearn\n\nfrom nltk.corpus import stopwords \n\nfrom scipy.sparse import csr_matrix\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.sparse.linalg import svds\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-17T14:03:32.517546Z","iopub.execute_input":"2024-11-17T14:03:32.518009Z","iopub.status.idle":"2024-11-17T14:03:37.135698Z","shell.execute_reply.started":"2024-11-17T14:03:32.517962Z","shell.execute_reply":"2024-11-17T14:03:37.134226Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class ContentBasedRecommender:\n        \n    MODEL_NAME = 'Content-Based'\n    \n    def __init__(self, items_df=None, item_ids=None, user_profiles=None, tfidf_matrix=None):\n        self.item_ids = item_ids\n        self.items_df = items_df\n        self.user_profiles = user_profiles\n        self.tfidf_matrix = tfidf_matrix\n        \n    def get_model_name(self):\n        return self.MODEL_NAME\n        \n    def _get_similar_items_to_user_profile(self, person_id, topn=1000):\n        #Computes the cosine similarity between the user profile and all item profiles\n        cosine_similarities = cosine_similarity(self.user_profiles[person_id], self.tfidf_matrix)\n        #Gets the top similar items\n        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n        #Sort the similar items by similarity\n        similar_items = sorted([(self.item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n        return similar_items\n        \n    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n        similar_items = self._get_similar_items_to_user_profile(user_id)\n        #Ignores items the user has already interacted\n        similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\n        \n        recommendations_df = pd.DataFrame(similar_items_filtered, columns=['contentId', 'recStrength']) \\\n                                    .head(topn)\n\n        if verbose:\n            if self.items_df is None:\n                raise Exception('\"items_df\" is required in verbose mode')\n\n            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n                                                          left_on = 'contentId', \n                                                          right_on = 'contentId')[['recStrength', 'contentId', 'title', 'url', 'lang']]\n\n\n        return recommendations_df","metadata":{"execution":{"iopub.status.busy":"2024-11-17T14:04:33.464850Z","iopub.execute_input":"2024-11-17T14:04:33.465496Z","iopub.status.idle":"2024-11-17T14:04:33.480755Z","shell.execute_reply.started":"2024-11-17T14:04:33.465437Z","shell.execute_reply":"2024-11-17T14:04:33.479372Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class CFRecommender:\n        \n    MODEL_NAME = 'Collaborative Filtering'\n    \n    def __init__(self, cf_predictions_df, items_df=None):\n        self.cf_predictions_df = cf_predictions_df\n        self.items_df = items_df\n        \n    def get_model_name(self):\n        return self.MODEL_NAME\n        \n    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n        # Get and sort the user's predictions\n        sorted_user_predictions = self.cf_predictions_df[user_id].sort_values(ascending=False) \\\n                                    .reset_index().rename(columns={user_id: 'recStrength'})\n\n        # Recommend the highest predicted rating movies that the user hasn't seen yet.\n        recommendations_df = sorted_user_predictions[~sorted_user_predictions['contentId'].isin(items_to_ignore)] \\\n                               .sort_values('recStrength', ascending = False) \\\n                               .head(topn)\n\n        if verbose:\n            if self.items_df is None:\n                raise Exception('\"items_df\" is required in verbose mode')\n\n            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n                                                          left_on = 'contentId', \n                                                          right_on = 'contentId')[['recStrength', 'contentId', 'title', 'url', 'lang']]\n\n\n        return recommendations_df","metadata":{"execution":{"iopub.status.busy":"2024-11-17T14:05:28.416243Z","iopub.execute_input":"2024-11-17T14:05:28.416737Z","iopub.status.idle":"2024-11-17T14:05:28.429513Z","shell.execute_reply.started":"2024-11-17T14:05:28.416693Z","shell.execute_reply":"2024-11-17T14:05:28.428001Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class PopularityRecommender:\n        \n    MODEL_NAME = 'Popularity'\n    \n    def __init__(self, popularity_df, items_df=None):\n        self.popularity_df = popularity_df\n        self.items_df = items_df\n        \n    def get_model_name(self):\n        return self.MODEL_NAME\n        \n    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n        # Recommend the more popular items that the user hasn't seen yet.\n        recommendations_df = self.popularity_df[~self.popularity_df['contentId'].isin(items_to_ignore)] \\\n                               .sort_values('eventStrength', ascending = False) \\\n                               .head(topn)\n\n        if verbose:\n            if self.items_df is None:\n                raise Exception('\"items_df\" is required in verbose mode')\n\n            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n                                                          left_on = 'contentId', \n                                                          right_on = 'contentId')[['eventStrength', 'contentId', 'title', 'url', 'lang']]\n    \n\n        return recommendations_df\n\n\n\ndef run_starting_code(articles_df, interactions_df):\n\n\n\n    def smooth_user_preference(x):\n        return math.log(1+x, 2)\n\n    def get_items_interacted(person_id, interactions_df):\n        # Get the user's data and merge in the movie information.\n        interacted_items = interactions_df.loc[person_id]['contentId']\n        return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])\n\n    def get_item_profile(item_id):\n        idx = item_ids.index(item_id)\n        item_profile = tfidf_matrix[idx:idx+1]\n        return item_profile\n\n    def get_item_profiles(ids):\n        item_profiles_list = [get_item_profile(x) for x in ids]\n        item_profiles = scipy.sparse.vstack(item_profiles_list)\n        return item_profiles\n\n    def build_users_profile(person_id, interactions_indexed_df):\n        interactions_person_df = interactions_indexed_df.loc[person_id]\n        user_item_profiles = get_item_profiles(interactions_person_df['contentId'])\n        \n        user_item_strengths = np.array(interactions_person_df['eventStrength']).reshape(-1,1)\n        #Weighted average of item profiles by the interactions strength\n        user_item_strengths_weighted_avg = np.sum(user_item_profiles.multiply(user_item_strengths), axis=0) / np.sum(user_item_strengths)\n        user_profile_norm = sklearn.preprocessing.normalize(np.array(user_item_strengths_weighted_avg))\n        return user_profile_norm\n\n    def build_users_profiles(): \n        interactions_indexed_df = interactions_full_df[interactions_full_df['contentId'] \\\n                                                       .isin(articles_df['contentId'])].set_index('personId')\n        user_profiles = {}\n        for person_id in interactions_indexed_df.index.unique():\n            user_profiles[person_id] = build_users_profile(person_id, interactions_indexed_df)\n        return user_profiles","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the datasets\ninteractions_df = pd.read_csv(\"/kaggle/input/lab7dataset/ccai422_lab07_data_users_interactions.csv\")\narticles_df = pd.read_csv(\"/kaggle/input/lab7dataset/ccai422_lab07_data_shared_articles.csv\")\n\n# Display the first few rows to verify the data is loaded correctly\nprint(interactions_df.head(10))\nprint(articles_df.head(10))\n\n# Event type strength mapping\nevent_type_strength = {\n    'VIEW': 1.0,\n    'LIKE': 2.0,\n    'BOOKMARK': 2.5,\n    'FOLLOW': 3.0,\n    'COMMENT CREATED': 4.0\n}\n\n# Add eventStrength column based on eventType\ninteractions_df['eventStrength'] = interactions_df['eventType'].apply(lambda x: event_type_strength.get(x, 0))\n\n# Filter users with at least 5 interactions\nusers_interactions_count_df = interactions_df.groupby(['personId', 'contentId']).size().groupby('personId').size()\nusers_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index(name='interactionCount')\n\n# Merge filtered users back into the interactions data\ninteractions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df[['personId']], how='inner', on='personId')\n\n# Aggregate event strength for user-content interactions\ninteractions_full_df = interactions_from_selected_users_df.groupby(['personId', 'contentId'])['eventStrength'].sum().reset_index()\n\n# Compute item popularity\nitem_popularity_df = interactions_full_df.groupby('contentId')['eventStrength'].sum().sort_values(ascending=False).reset_index()\n\n# Define stopwords for vectorization\nstopwords_list = stopwords.words('english') + stopwords.words('portuguese')\n\n# Train a TF-IDF model\nvectorizer = TfidfVectorizer(\n    analyzer='word',\n    ngram_range=(1, 2),\n    min_df=0.003,\n    max_df=0.5,\n    max_features=5000,\n    stop_words=stopwords_list\n)\ntfidf_matrix = vectorizer.fit_transform(articles_df['title'] + \" \" + articles_df['text'])\ntfidf_feature_names = vectorizer.get_feature_names_out()\n\n# User profiles creation\ndef build_users_profiles():\n    user_profiles = {}\n    for person_id in interactions_full_df['personId'].unique():\n        user_interactions = interactions_full_df[interactions_full_df['personId'] == person_id]\n        user_profile = np.sum(\n            tfidf_matrix[user_interactions['contentId'].map(lambda x: articles_df[articles_df['contentId'] == x].index[0]).values],\n            axis=0\n        )\n        user_profiles[person_id] = user_profile\n    return user_profiles\n\nuser_profiles = build_users_profiles()\n\n# Example: Sorting and displaying top tokens in the user profile\nuser_id_example = list(user_profiles.keys())[0]  # Retrieve a sample user ID\nexample_profile = user_profiles[user_id_example]  # Retrieve the user profile (vector)\n\n# Ensure example_profile is properly flattened into a numerical array\nexample_profile = np.array(example_profile).flatten()\n\n# Fix: Ensure correct type for sorting by numerical relevance\nsorted_tokens = sorted(\n    zip(tfidf_feature_names, example_profile),\n    key=lambda x: -x[1]  # Sort by relevance score in descending order\n)[:20]\n\n# Display the top tokens and their relevance\nprint(\"Top tokens for user profile:\\n\", pd.DataFrame(sorted_tokens, columns=['token', 'relevance']))\n\n# Pivot table for collaborative filtering\nusers_items_pivot_matrix_df = interactions_full_df.pivot(index='personId', columns='contentId', values='eventStrength').fillna(0)\nusers_items_pivot_sparse_matrix = csr_matrix(users_items_pivot_matrix_df.values)\n\n# Matrix factorization\nNUMBER_OF_FACTORS_MF = 15\nU, sigma, Vt = np.linalg.svd(users_items_pivot_sparse_matrix.toarray(), full_matrices=False)\nsigma = np.diag(sigma)\n\n# Predicted ratings\nall_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt)\ncf_preds_df = pd.DataFrame(all_user_predicted_ratings, index=users_items_pivot_matrix_df.index, columns=users_items_pivot_matrix_df.columns)\n\n# Return models\ndef create_models():\n    return {\n        'popularity_model': item_popularity_df,\n        'cf_recommender': cf_preds_df,\n        'content_based_recommender': user_profiles\n    }\n\nmodels = create_models()\nprint(\"Models created successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-17T14:31:24.356084Z","iopub.execute_input":"2024-11-17T14:31:24.356721Z","iopub.status.idle":"2024-11-17T14:31:55.348010Z","shell.execute_reply.started":"2024-11-17T14:31:24.356662Z","shell.execute_reply":"2024-11-17T14:31:55.346249Z"},"trusted":true},"outputs":[{"name":"stdout","text":"    timestamp eventType            contentId             personId  \\\n0  1465413032      VIEW -3499919498720038879 -8845298781299428018   \n1  1465412560      VIEW  8890720798209849691 -1032019229384696495   \n2  1465416190      VIEW   310515487419366995 -1130272294246983140   \n3  1465413895    FOLLOW   310515487419366995   344280948527967603   \n4  1465412290      VIEW -7820640624231356730  -445337111692715325   \n5  1465413742      VIEW   310515487419366995 -8763398617720485024   \n6  1465415950      VIEW -8864073373672512525  3609194402293569455   \n7  1465415066      VIEW -1492913151930215984  4254153380739593270   \n8  1465413762      VIEW   310515487419366995   344280948527967603   \n9  1465413771      VIEW  3064370296170038610  3609194402293569455   \n\n             sessionId                                          userAgent  \\\n0  1264196770339959068                                                NaN   \n1  3621737643587579081  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2...   \n2  2631864456530402479                                                NaN   \n3 -3167637573980064150                                                NaN   \n4  5611481178424124714                                                NaN   \n5  1395789369402380392  Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebK...   \n6  1143207167886864524                                                NaN   \n7  8743229464706506141  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...   \n8 -3167637573980064150                                                NaN   \n9  1143207167886864524                                                NaN   \n\n  userRegion userCountry  \n0        NaN         NaN  \n1         NY          US  \n2        NaN         NaN  \n3        NaN         NaN  \n4        NaN         NaN  \n5         MG          BR  \n6        NaN         NaN  \n7         SP          BR  \n8        NaN         NaN  \n9        NaN         NaN  \n    timestamp        eventType            contentId       authorPersonId  \\\n0  1459192779  CONTENT REMOVED -6451309518266745024  4340306774493623681   \n1  1459193988   CONTENT SHARED -4110354420726924665  4340306774493623681   \n2  1459194146   CONTENT SHARED -7292285110016212249  4340306774493623681   \n3  1459194474   CONTENT SHARED -6151852268067518688  3891637997717104548   \n4  1459194497   CONTENT SHARED  2448026894306402386  4340306774493623681   \n5  1459194522   CONTENT SHARED -2826566343807132236  4340306774493623681   \n6  1459194557   CONTENT SHARED -2148899391355011268  4340306774493623681   \n7  1459194599   CONTENT SHARED  4119190424078847945  4340306774493623681   \n8  1459194751   CONTENT SHARED -7926018713416777892  4340306774493623681   \n9  1459194842   CONTENT SHARED  3353902017498793780  4340306774493623681   \n\n       authorSessionId authorUserAgent authorRegion authorCountry contentType  \\\n0  8940341205206233829             NaN          NaN           NaN        HTML   \n1  8940341205206233829             NaN          NaN           NaN        HTML   \n2  8940341205206233829             NaN          NaN           NaN        HTML   \n3 -1457532940883382585             NaN          NaN           NaN        HTML   \n4  8940341205206233829             NaN          NaN           NaN        HTML   \n5  8940341205206233829             NaN          NaN           NaN        HTML   \n6  8940341205206233829             NaN          NaN           NaN        HTML   \n7  8940341205206233829             NaN          NaN           NaN        HTML   \n8  8940341205206233829             NaN          NaN           NaN        HTML   \n9  8940341205206233829             NaN          NaN           NaN        HTML   \n\n                                                 url  \\\n0  http://www.nytimes.com/2016/03/28/business/dea...   \n1  http://www.nytimes.com/2016/03/28/business/dea...   \n2  http://cointelegraph.com/news/bitcoin-future-w...   \n3  https://cloudplatform.googleblog.com/2016/03/G...   \n4  https://bitcoinmagazine.com/articles/ibm-wants...   \n5  http://www.coindesk.com/ieee-blockchain-oxford...   \n6  http://www.newsbtc.com/2016/03/28/banks-need-c...   \n7  https://bitcoinmagazine.com/articles/blockchai...   \n8  https://news.bitcoin.com/conglomerates-intervi...   \n9  https://www.cryptocoinsnews.com/ethereum-rise-...   \n\n                                               title  \\\n0  Ethereum, a Virtual Currency, Enables Transact...   \n1  Ethereum, a Virtual Currency, Enables Transact...   \n2  Bitcoin Future: When GBPcoin of Branson Wins O...   \n3                       Google Data Center 360Â° Tour   \n4  IBM Wants to \"Evolve the Internet\" With Blockc...   \n5  IEEE to Talk Blockchain at Cloud Computing Oxf...   \n6  Banks Need To Collaborate With Bitcoin and Fin...   \n7  Blockchain Technology Could Put Bank Auditors ...   \n8  Why Decentralized Conglomerates Will Scale Bet...   \n9  The Rise And Growth of Ethereum Gets Mainstrea...   \n\n                                                text lang  \n0  All of this work is still very early. The firs...   en  \n1  All of this work is still very early. The firs...   en  \n2  The alarm clock wakes me at 8:00 with stream o...   en  \n3  We're excited to share the Google Data Center ...   en  \n4  The Aite Group projects the blockchain market ...   en  \n5  One of the largest and oldest organizations fo...   en  \n6  It will take time until banks come around to t...   en  \n7  When most people think about computers and rob...   en  \n8  Bitcoin.com spoke with the OpenLedger CEO, Ron...   en  \n9  Ethereum, considered by many to be the most pr...   en  \nTop tokens for user profile:\n         token  relevance\n0      google   3.166974\n1       cloud   1.459942\n2     android   1.429904\n3     digital   1.145232\n4        code   1.061235\n5       apple   1.048931\n6   microsoft   1.004650\n7    business   0.990168\n8        time   0.970989\n9       dados   0.958143\n10    youtube   0.929289\n11        app   0.914700\n12    company   0.901409\n13   internet   0.872907\n14     people   0.856322\n15    product   0.856264\n16     mobile   0.851095\n17       team   0.838559\n18  companies   0.813849\n19       mall   0.813170\nModels created successfully.\n","output_type":"stream"}],"execution_count":7}]}